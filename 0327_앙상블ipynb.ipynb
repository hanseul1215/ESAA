{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "0327_앙상블ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMGjRDU0EvWLUz5trRjrNzo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hanseul1215/ESAA_study/blob/master/0327_%EC%95%99%EC%83%81%EB%B8%94ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7.1 투표 기반 분류기 \n",
        "- 개별 분류기의 예측을 모아서 가장 많이 선택된 클래스를 예측 : 직접 투표(hard voting) \n",
        "- 개별 분류기의 예측을 평균 내어 확률이 가장 높은 클래스를 예측 : 간접 투표(soft voting)  \n",
        "(분류기가 클래스의 확률을 예측할 수 있어야 함)"
      ],
      "metadata": {
        "id": "JWFnzIjPyzGt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import make_moons\n",
        "\n",
        "X, y = make_moons(n_samples=500, noise=0.30, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
      ],
      "metadata": {
        "id": "ddXowk-cGskE"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fn-KlyBxvL2",
        "outputId": "2c1a01ca-cc63-41d0-95ef-dac0fd064273"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VotingClassifier(estimators=[('lr', LogisticRegression()),\n",
              "                             ('rf', RandomForestClassifier()), ('svc', SVC())])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "log_clf = LogisticRegression()\n",
        "rnd_clf = RandomForestClassifier()\n",
        "svm_clf = SVC()\n",
        "\n",
        "voting_clf = VotingClassifier(\n",
        "    estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)], voting='hard'\n",
        ")\n",
        "voting_clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "for clf in (log_clf, rnd_clf, svm_clf, voting_clf):\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "6Ca4vzLLGxKK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d8c229a-a1cc-4194-ecb3-8dc03a181b86"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression 0.864\n",
            "RandomForestClassifier 0.88\n",
            "SVC 0.896\n",
            "VotingClassifier 0.904\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7.2 배깅과 페이스팅\n",
        "- 배깅 (bootstrap aggregating): 훈련 세트에서 중복을 허용하여 샘플링하는 방식\n",
        "- 페이스팅: 중복을 허용하지 않고 샘플링하는 방식\n",
        "## 7.2.1 사이킷런의 배깅과 페이스팅\n",
        "- BagginfClassifier/Regressor\n",
        "- 부트스트래핑은 각 예측기가 학습하는 서브셋에 다양성을 증가 (-> 분산 감소) 시키므로 배깅이 페이스팅보다 편향이 더 높다."
      ],
      "metadata": {
        "id": "asygROyxhaSq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "bag_clf = BaggingClassifier(\n",
        "    DecisionTreeClassifier(), n_estimators=500,\n",
        "    max_samples=100, bootstrap=True, random_state=42)\n",
        "bag_clf.fit(X_train, y_train)\n",
        "y_pred = bag_clf.predict(X_test)"
      ],
      "metadata": {
        "id": "oYGWp2W_gKtf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.2.2 oob 평가\n",
        "- oob (out of bag) 샘플: 선택되지 않은 훈련 샘플의 나머지 \n",
        "- 훈련 후 oob 샘플로 평가하는 방법!"
      ],
      "metadata": {
        "id": "WTSOWyA7j4D_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bag_clf = BaggingClassifier(\n",
        "    DecisionTreeClassifier(), n_estimators=500,\n",
        "    bootstrap=True, oob_score=True, random_state=40)\n",
        "bag_clf.fit(X_train, y_train)\n",
        "bag_clf.oob_score_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXiDXEoGjBus",
        "outputId": "7f111cd1-c3a8-4d27-9c8c-b7dcaecfbecd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8986666666666666"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "y_pred = bag_clf.predict(X_test)\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9Y4u7tmkfpB",
        "outputId": "184045d1-0f45-4845-a49c-7164dca3c085"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.912"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# oob 샘플에 대한 결정 함수 값 (훈련 샘플의 클래스 확률)\n",
        "bag_clf.oob_decision_function_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6g0UOPKk_-k",
        "outputId": "1d3de428-7f85-4a53-ce01-9d7ddfec277f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.32275132, 0.67724868],\n",
              "       [0.34117647, 0.65882353],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.09497207, 0.90502793],\n",
              "       [0.31147541, 0.68852459],\n",
              "       [0.01754386, 0.98245614],\n",
              "       [0.97109827, 0.02890173],\n",
              "       [0.97765363, 0.02234637],\n",
              "       [0.74404762, 0.25595238],\n",
              "       [0.        , 1.        ],\n",
              "       [0.7173913 , 0.2826087 ],\n",
              "       [0.85026738, 0.14973262],\n",
              "       [0.97222222, 0.02777778],\n",
              "       [0.0625    , 0.9375    ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.97837838, 0.02162162],\n",
              "       [0.94642857, 0.05357143],\n",
              "       [1.        , 0.        ],\n",
              "       [0.01704545, 0.98295455],\n",
              "       [0.39473684, 0.60526316],\n",
              "       [0.88700565, 0.11299435],\n",
              "       [1.        , 0.        ],\n",
              "       [0.97790055, 0.02209945],\n",
              "       [0.        , 1.        ],\n",
              "       [0.99428571, 0.00571429],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.62569832, 0.37430168],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.13402062, 0.86597938],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.38251366, 0.61748634],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.27093596, 0.72906404],\n",
              "       [0.34146341, 0.65853659],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.00531915, 0.99468085],\n",
              "       [0.98843931, 0.01156069],\n",
              "       [0.91428571, 0.08571429],\n",
              "       [0.97282609, 0.02717391],\n",
              "       [0.98019802, 0.01980198],\n",
              "       [0.        , 1.        ],\n",
              "       [0.07361963, 0.92638037],\n",
              "       [0.98019802, 0.01980198],\n",
              "       [0.0052356 , 0.9947644 ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.97790055, 0.02209945],\n",
              "       [0.8       , 0.2       ],\n",
              "       [0.42424242, 0.57575758],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.66477273, 0.33522727],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.86781609, 0.13218391],\n",
              "       [1.        , 0.        ],\n",
              "       [0.56725146, 0.43274854],\n",
              "       [0.1576087 , 0.8423913 ],\n",
              "       [0.66492147, 0.33507853],\n",
              "       [0.91709845, 0.08290155],\n",
              "       [0.        , 1.        ],\n",
              "       [0.16759777, 0.83240223],\n",
              "       [0.87434555, 0.12565445],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.995     , 0.005     ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.07878788, 0.92121212],\n",
              "       [0.05418719, 0.94581281],\n",
              "       [0.29015544, 0.70984456],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.83040936, 0.16959064],\n",
              "       [0.01092896, 0.98907104],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.21465969, 0.78534031],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.94660194, 0.05339806],\n",
              "       [0.77094972, 0.22905028],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.16574586, 0.83425414],\n",
              "       [0.65306122, 0.34693878],\n",
              "       [0.        , 1.        ],\n",
              "       [0.02564103, 0.97435897],\n",
              "       [0.50555556, 0.49444444],\n",
              "       [1.        , 0.        ],\n",
              "       [0.03208556, 0.96791444],\n",
              "       [0.99435028, 0.00564972],\n",
              "       [0.23699422, 0.76300578],\n",
              "       [0.49509804, 0.50490196],\n",
              "       [0.9947644 , 0.0052356 ],\n",
              "       [0.00555556, 0.99444444],\n",
              "       [0.98963731, 0.01036269],\n",
              "       [0.26153846, 0.73846154],\n",
              "       [0.92972973, 0.07027027],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.80113636, 0.19886364],\n",
              "       [1.        , 0.        ],\n",
              "       [0.0106383 , 0.9893617 ],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.98181818, 0.01818182],\n",
              "       [1.        , 0.        ],\n",
              "       [0.01036269, 0.98963731],\n",
              "       [0.97752809, 0.02247191],\n",
              "       [0.99453552, 0.00546448],\n",
              "       [0.01960784, 0.98039216],\n",
              "       [0.17857143, 0.82142857],\n",
              "       [0.98387097, 0.01612903],\n",
              "       [0.29533679, 0.70466321],\n",
              "       [0.98295455, 0.01704545],\n",
              "       [0.        , 1.        ],\n",
              "       [0.00561798, 0.99438202],\n",
              "       [0.75690608, 0.24309392],\n",
              "       [0.38624339, 0.61375661],\n",
              "       [0.40625   , 0.59375   ],\n",
              "       [0.87368421, 0.12631579],\n",
              "       [0.92462312, 0.07537688],\n",
              "       [0.05181347, 0.94818653],\n",
              "       [0.82802548, 0.17197452],\n",
              "       [0.01546392, 0.98453608],\n",
              "       [0.        , 1.        ],\n",
              "       [0.02298851, 0.97701149],\n",
              "       [0.9726776 , 0.0273224 ],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.01041667, 0.98958333],\n",
              "       [0.        , 1.        ],\n",
              "       [0.03804348, 0.96195652],\n",
              "       [0.02040816, 0.97959184],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.94915254, 0.05084746],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.99462366, 0.00537634],\n",
              "       [0.        , 1.        ],\n",
              "       [0.39378238, 0.60621762],\n",
              "       [0.33152174, 0.66847826],\n",
              "       [0.00609756, 0.99390244],\n",
              "       [0.        , 1.        ],\n",
              "       [0.3172043 , 0.6827957 ],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.00588235, 0.99411765],\n",
              "       [0.        , 1.        ],\n",
              "       [0.98924731, 0.01075269],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.62893082, 0.37106918],\n",
              "       [0.92344498, 0.07655502],\n",
              "       [0.        , 1.        ],\n",
              "       [0.99526066, 0.00473934],\n",
              "       [1.        , 0.        ],\n",
              "       [0.98888889, 0.01111111],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.06989247, 0.93010753],\n",
              "       [1.        , 0.        ],\n",
              "       [0.03608247, 0.96391753],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.02185792, 0.97814208],\n",
              "       [1.        , 0.        ],\n",
              "       [0.95808383, 0.04191617],\n",
              "       [0.78362573, 0.21637427],\n",
              "       [0.56650246, 0.43349754],\n",
              "       [0.        , 1.        ],\n",
              "       [0.18023256, 0.81976744],\n",
              "       [1.        , 0.        ],\n",
              "       [0.93121693, 0.06878307],\n",
              "       [0.97175141, 0.02824859],\n",
              "       [1.        , 0.        ],\n",
              "       [0.00531915, 0.99468085],\n",
              "       [0.        , 1.        ],\n",
              "       [0.43010753, 0.56989247],\n",
              "       [0.85858586, 0.14141414],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.00558659, 0.99441341],\n",
              "       [0.        , 1.        ],\n",
              "       [0.96923077, 0.03076923],\n",
              "       [0.        , 1.        ],\n",
              "       [0.21649485, 0.78350515],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.98477157, 0.01522843],\n",
              "       [0.8       , 0.2       ],\n",
              "       [0.99441341, 0.00558659],\n",
              "       [0.        , 1.        ],\n",
              "       [0.09497207, 0.90502793],\n",
              "       [0.99492386, 0.00507614],\n",
              "       [0.01714286, 0.98285714],\n",
              "       [0.        , 1.        ],\n",
              "       [0.02747253, 0.97252747],\n",
              "       [1.        , 0.        ],\n",
              "       [0.77005348, 0.22994652],\n",
              "       [0.        , 1.        ],\n",
              "       [0.90229885, 0.09770115],\n",
              "       [0.98387097, 0.01612903],\n",
              "       [0.22222222, 0.77777778],\n",
              "       [0.20348837, 0.79651163],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.20338983, 0.79661017],\n",
              "       [0.98181818, 0.01818182],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.98969072, 0.01030928],\n",
              "       [0.        , 1.        ],\n",
              "       [0.48663102, 0.51336898],\n",
              "       [1.        , 0.        ],\n",
              "       [0.00529101, 0.99470899],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.08379888, 0.91620112],\n",
              "       [0.12352941, 0.87647059],\n",
              "       [0.99415205, 0.00584795],\n",
              "       [0.03517588, 0.96482412],\n",
              "       [1.        , 0.        ],\n",
              "       [0.39790576, 0.60209424],\n",
              "       [0.05434783, 0.94565217],\n",
              "       [0.53191489, 0.46808511],\n",
              "       [0.51898734, 0.48101266],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.60869565, 0.39130435],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.24157303, 0.75842697],\n",
              "       [0.81578947, 0.18421053],\n",
              "       [0.08717949, 0.91282051],\n",
              "       [0.99453552, 0.00546448],\n",
              "       [0.82142857, 0.17857143],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.11904762, 0.88095238],\n",
              "       [0.04188482, 0.95811518],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.89150943, 0.10849057],\n",
              "       [0.19230769, 0.80769231],\n",
              "       [0.95238095, 0.04761905],\n",
              "       [0.00515464, 0.99484536],\n",
              "       [0.59375   , 0.40625   ],\n",
              "       [0.07692308, 0.92307692],\n",
              "       [0.99484536, 0.00515464],\n",
              "       [0.83684211, 0.16315789],\n",
              "       [0.        , 1.        ],\n",
              "       [0.99484536, 0.00515464],\n",
              "       [0.95360825, 0.04639175],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.26395939, 0.73604061],\n",
              "       [0.98461538, 0.01538462],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.00574713, 0.99425287],\n",
              "       [0.85142857, 0.14857143],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.75301205, 0.24698795],\n",
              "       [0.8969697 , 0.1030303 ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.75555556, 0.24444444],\n",
              "       [0.48863636, 0.51136364],\n",
              "       [0.        , 1.        ],\n",
              "       [0.92473118, 0.07526882],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.87709497, 0.12290503],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.74752475, 0.25247525],\n",
              "       [0.09146341, 0.90853659],\n",
              "       [0.42268041, 0.57731959],\n",
              "       [0.22395833, 0.77604167],\n",
              "       [0.        , 1.        ],\n",
              "       [0.87046632, 0.12953368],\n",
              "       [0.78212291, 0.21787709],\n",
              "       [0.00507614, 0.99492386],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.02884615, 0.97115385],\n",
              "       [0.96      , 0.04      ],\n",
              "       [0.93478261, 0.06521739],\n",
              "       [1.        , 0.        ],\n",
              "       [0.50731707, 0.49268293],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.01604278, 0.98395722],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.96987952, 0.03012048],\n",
              "       [0.        , 1.        ],\n",
              "       [0.05172414, 0.94827586],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.99494949, 0.00505051],\n",
              "       [0.01675978, 0.98324022],\n",
              "       [1.        , 0.        ],\n",
              "       [0.14583333, 0.85416667],\n",
              "       [0.        , 1.        ],\n",
              "       [0.00546448, 0.99453552],\n",
              "       [0.        , 1.        ],\n",
              "       [0.41836735, 0.58163265],\n",
              "       [0.13095238, 0.86904762],\n",
              "       [0.22110553, 0.77889447],\n",
              "       [1.        , 0.        ],\n",
              "       [0.97647059, 0.02352941],\n",
              "       [0.21195652, 0.78804348],\n",
              "       [0.98882682, 0.01117318],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.96428571, 0.03571429],\n",
              "       [0.34554974, 0.65445026],\n",
              "       [0.98235294, 0.01764706],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.99465241, 0.00534759],\n",
              "       [0.        , 1.        ],\n",
              "       [0.06043956, 0.93956044],\n",
              "       [0.98214286, 0.01785714],\n",
              "       [1.        , 0.        ],\n",
              "       [0.03108808, 0.96891192],\n",
              "       [0.58854167, 0.41145833]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7.3 랜덤 패치와 랜덤 서브스페이스\n",
        "- 특성 샘플링: BagginClassifier의 max_features, bootstrap_features 두 매개변수로 조절 \n",
        "- 랜덤 패치: 훈련 특성과 샘플을 모두 샘플링하는 것\n",
        "- 랜덤 서브스페이스: 훈련 샘플을 모두 사용하고 특성은 샘플링하는 것"
      ],
      "metadata": {
        "id": "IpBi4lrFl8la"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7.4 랜덤 포레스트\n",
        "- 일반적으로 배깅(or 페이스팅)을 적용한 결정 트리의 앙상블\n",
        "- 무작위성  \n",
        "노드를 분할할 때 전체 특성 중에서 최선의 특성을 찾는 대신 무작위로 선택한 특성 후보 중에서 최적의 특성을 찾는다.  \n",
        ">편향 손해, 분산 낮춰"
      ],
      "metadata": {
        "id": "pB7EWQ0XqCf1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, random_state=42)\n",
        "rnd_clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred_rf = rnd_clf.predict(X_test)"
      ],
      "metadata": {
        "id": "4xAbez3Ml6oX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rf와 유사하게 만듦\n",
        "bag_clf = BaggingClassifier(\n",
        "    DecisionTreeClassifier(max_features=\"sqrt\", max_leaf_nodes=16),\n",
        "    n_estimators=500, random_state=42)"
      ],
      "metadata": {
        "id": "36nB27D-q3aF"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.4.1 엑스트라 트리 (익스트림 랜덤 트리)\n",
        "- 극단적으로 무작위한 트리의 랜덤 포레스트\n",
        "- rf보다 훨씬 빠름"
      ],
      "metadata": {
        "id": "TIP4Epv7rmKF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.4.2 특성 중요도\n",
        "- rf는 특성의 상대적 중요도를 측정하기 쉬움"
      ],
      "metadata": {
        "id": "bIv9Lb-nsB1l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "iris = load_iris()\n",
        "rnd_clf = RandomForestClassifier(n_estimators=500, random_state=42)\n",
        "rnd_clf.fit(iris[\"data\"], iris[\"target\"])\n",
        "for name, score in zip(iris[\"feature_names\"], rnd_clf.feature_importances_):\n",
        "    print(name, score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCziD7WjrkYf",
        "outputId": "0548e893-d5d5-40eb-de59-efd5613d4a03"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sepal length (cm) 0.11249225099876375\n",
            "sepal width (cm) 0.02311928828251033\n",
            "petal length (cm) 0.4410304643639577\n",
            "petal width (cm) 0.4233579963547682\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7.5 부스팅\n",
        "약한 학습기를 여러 개 연결하여 강한 학습기를 만드는 앙상블 방법\n",
        "## 7.5.1 에이다부스트 \n",
        "> 과소적합했던 훈련 샘플의 가중치를 더 높여 보완하는 방법  \n",
        "1) 정확한 예측기일수록 가중치를 더 높인다.  \n",
        "2) 샘플의 가중치를 업데이트하고 정규화한다.  \n",
        "3) 새 예측기가 업데이트된 가중치를 사용해 훈련되고 전체 과정을 반복한다.  \n",
        "4) ㅇ가중치의 합이 가장 큰 클래스가 예측 결과가 된다.\n"
      ],
      "metadata": {
        "id": "7FH79rxds2Bu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "ada_clf = AdaBoostClassifier(\n",
        "    DecisionTreeClassifier(max_depth=1), n_estimators=200,\n",
        "    algorithm=\"SAMME.R\", learning_rate=0.5, random_state=42)\n",
        "ada_clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNtWQv7Dscb3",
        "outputId": "ac09cdd2-249f-4607-c1c0-a9842e4be128"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1),\n",
              "                   learning_rate=0.5, n_estimators=200, random_state=42)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 7.5.2 그레이디언트 부스팅\n",
        "- ada처럼 샘플의 가중치를 수정하는 대신 이전 예측기가 만든 잔여 오차에 새로운 예측기를 학습시킨다."
      ],
      "metadata": {
        "id": "hhdqUFIrumIl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.random.seed(42)\n",
        "X = np.random.rand(100, 1) - 0.5\n",
        "y = 3*X[:, 0]**2 + 0.05 * np.random.randn(100)"
      ],
      "metadata": {
        "id": "eu9qrV54u9_6"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "tree_reg1 = DecisionTreeRegressor(max_depth=2, random_state=42)\n",
        "tree_reg1.fit(X, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FlD4Tb3uj-k",
        "outputId": "c3f3bdf5-caf6-4ee9-fdee-e7cda91b421e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeRegressor(max_depth=2, random_state=42)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y2 = y - tree_reg1.predict(X)\n",
        "tree_reg2 = DecisionTreeRegressor(max_depth=2, random_state=42)\n",
        "tree_reg2.fit(X, y2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrn04bOsvEnR",
        "outputId": "f9645df2-7c42-4f3c-c881-28501fefda56"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeRegressor(max_depth=2, random_state=42)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y3 = y2 - tree_reg2.predict(X)\n",
        "tree_reg3 = DecisionTreeRegressor(max_depth=2, random_state=42)\n",
        "tree_reg3.fit(X, y3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kz-J2fzVvItf",
        "outputId": "e362655e-7786-4b95-a0a3-dc68707d2bf5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeRegressor(max_depth=2, random_state=42)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "gbrt = GradientBoostingRegressor(max_depth=2, n_estimators=3, learning_rate=1.0, random_state=42)\n",
        "gbrt.fit(X, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6yWabiTvM5d",
        "outputId": "edd67149-e10b-4252-bed4-2245c1d99868"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GradientBoostingRegressor(learning_rate=1.0, max_depth=2, n_estimators=3,\n",
              "                          random_state=42)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "축소: learning_rate 매개변수를 낮게 설정해 일반적으로 예측의 성능을 좋게한다."
      ],
      "metadata": {
        "id": "4UvgwMqQvweE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 최적의 트리 수를 찾기 위해 조기 종료 기법 사용\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=49)\n",
        "\n",
        "gbrt = GradientBoostingRegressor(max_depth=2, n_estimators=120, random_state=42)\n",
        "gbrt.fit(X_train, y_train)\n",
        "\n",
        "errors = [mean_squared_error(y_val, y_pred)\n",
        "          for y_pred in gbrt.staged_predict(X_val)]\n",
        "bst_n_estimators = np.argmin(errors) + 1\n",
        "\n",
        "gbrt_best = GradientBoostingRegressor(max_depth=2, n_estimators=bst_n_estimators, random_state=42)\n",
        "gbrt_best.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9ITuSmevgb3",
        "outputId": "5d4b6fdb-77a4-4a32-dae1-d8a54258cebe"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GradientBoostingRegressor(max_depth=2, n_estimators=56, random_state=42)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gbrt = GradientBoostingRegressor(max_depth=2, warm_start=True, random_state=42)\n",
        "\n",
        "min_val_error = float(\"inf\")\n",
        "error_going_up = 0\n",
        "for n_estimators in range(1, 120):\n",
        "    gbrt.n_estimators = n_estimators\n",
        "    gbrt.fit(X_train, y_train)\n",
        "    y_pred = gbrt.predict(X_val)\n",
        "    val_error = mean_squared_error(y_val, y_pred)\n",
        "    if val_error < min_val_error:\n",
        "        min_val_error = val_error\n",
        "        error_going_up = 0\n",
        "    else:\n",
        "        error_going_up += 1\n",
        "        if error_going_up == 5:\n",
        "            break  # early stopping"
      ],
      "metadata": {
        "id": "6gE-C8HBwGbN"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "gbr -> subsample로 훈련 샘플의 비율 지정 가능\n",
        "- 편향은 높아지고 분산은 낮아짐, 훈련 속도 높임 -> 확률적 그레이디언트 부스팅"
      ],
      "metadata": {
        "id": "89S7Zb-FwW5e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.6 스태킹\n",
        "- 개별 예측기에서 각각 예측하고 마지막 예측기(블렌더, 메타학습기)에서 최종 예측\n",
        "- 블렌더 훈련에 홀드 아웃 이용"
      ],
      "metadata": {
        "id": "F1cQjyQbw2G2"
      }
    }
  ]
}